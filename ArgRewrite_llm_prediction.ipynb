{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import ast\n",
    "import re\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "\n",
    "\n",
    "from openai import OpenAI\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from statsmodels.stats.inter_rater import fleiss_kappa\n",
    "from statsmodels.stats import inter_rater as irr\n",
    "from collections import Counter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = \"YOUR_API_KEY\"\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test and train sets creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Path to the root directory (change to your root directory)\n",
    "root_dir = \"~/annotations\"\n",
    "\n",
    "# Subdirectories where the Excel files are stored\n",
    "subdirs = [\"A\", \"B\", \"C\", \"D\"]\n",
    "\n",
    "# Collect all Excel files from the subdirectories\n",
    "excel_files = []\n",
    "for subdir in subdirs:\n",
    "    path = os.path.join(root_dir, subdir, \"12\", \"*.xlsx\")\n",
    "    excel_files.extend(glob.glob(path))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Initialize an empty list to store the new rows for the DataFrame\n",
    "all_data = []\n",
    "\n",
    "# Function to extract document ID\n",
    "def extract_id(filename):\n",
    "    match = re.search(r\"Annotation_2018argrewrite_(\\d+)\", filename)\n",
    "    return match.group(1) if match else \"unknown\"\n",
    "\n",
    "\n",
    "# Function to handle Aligned Index and retrieve corresponding sentence(s)\n",
    "def get_text_after(aligned_index_str : str) -> str:\n",
    "    if aligned_index_str == \"DELETE\":\n",
    "        return \"\"  # Empty string for DELETE\n",
    "    try:\n",
    "        # Convert string like '1, 2, 3' to a list of integers\n",
    "        aligned_indices = list(map(int, aligned_index_str.split(\",\")))\n",
    "    except ValueError:\n",
    "        return None  # If conversion fails, return None\n",
    "\n",
    "    # Find corresponding \"Sentence Content\" in new_draft\n",
    "    text_after = []\n",
    "    for index in aligned_indices:\n",
    "        matching_rows = new_draft_df[new_draft_df[\"Sentence Index\"] == index]\n",
    "        for _, row in matching_rows.iterrows():\n",
    "            text_after.append(row[\"Sentence Content\"])\n",
    "\n",
    "    return \" \".join(text_after)  # Join sentences if there are multiple matches\n",
    "\n",
    "\n",
    "for file in excel_files:\n",
    "        # Read both sheets\n",
    "    old_draft_df = pd.read_excel(file, sheet_name=\"Old Draft\")\n",
    "    new_draft_df = pd.read_excel(file, sheet_name=\"New Draft\")\n",
    "\n",
    "    doc_id = extract_id(os.path.basename(file))  # Extract document ID\n",
    "    # Iterate over the rows in the old draft\n",
    "    for _, old_row in old_draft_df.iterrows():\n",
    "        # Check if \"Identical?\" == 0\n",
    "        if old_row[\"Identical?\"] == 0:\n",
    "            text_before = old_row[\"Sentence Content\"]  # Sentence from old draft\n",
    "            aligned_index = old_row[\"Aligned Index\"]  # Aligned Index in old draft\n",
    "            label = old_row[\"Revision Purpose Level 0\"]\n",
    "            \n",
    "            # Get corresponding \"Text After\" based on Aligned Index\n",
    "            text_after = get_text_after(str(aligned_index))  # Ensure it's a string\n",
    "            \n",
    "            # Add the new row to the new_data list\n",
    "            all_data.append({\n",
    "                \"Text Before\": text_before,\n",
    "                \"Text After\": text_after,\n",
    "                \"Label\": label,\n",
    "                \"Doc Id\": doc_id\n",
    "            })\n",
    "    for _, new_row in new_draft_df.iterrows():\n",
    "        if str(new_row[\"Aligned Index\"]) == \"ADD\":\n",
    "            text_before = \"\"\n",
    "            label = new_row[\"Revision Purpose Level 0\"]\n",
    "            text_after = new_row[\"Sentence Content\"]\n",
    "\n",
    "            all_data.append({\n",
    "                \"Text Before\": text_before,\n",
    "                \"Text After\": text_after,\n",
    "                \"Label\": label,\n",
    "                \"Doc Id\": doc_id\n",
    "            })\n",
    "# Create the new DataFrame\n",
    "merged_df_12 = pd.DataFrame(all_data)\n",
    "\n",
    "# Display or save the new DataFrame\n",
    "# merged_df.to_excel(\"merged_output.xlsx\", index=False)\n",
    "print(merged_df_12.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Path to the root directory (change to your root directory)\n",
    "root_dir = \"/home/nbl/llm-notebooks/data-bea/annotations\"\n",
    "\n",
    "# Subdirectories where the Excel files are stored\n",
    "subdirs = [\"A\", \"B\", \"C\", \"D\"]\n",
    "\n",
    "# Collect all Excel files from the subdirectories\n",
    "excel_files = []\n",
    "for subdir in subdirs:\n",
    "    path = os.path.join(root_dir, subdir, \"23\", \"*.xlsx\")\n",
    "    excel_files.extend(glob.glob(path))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Initialize an empty list to store the new rows for the DataFrame\n",
    "all_data = []\n",
    "\n",
    "# Function to extract document ID\n",
    "def extract_id(filename):\n",
    "    match = re.search(r\"Annotation_2018argrewrite_(\\d+)\", filename)\n",
    "    return match.group(1) if match else \"unknown\"\n",
    "\n",
    "\n",
    "# Function to handle Aligned Index and retrieve corresponding sentence(s)\n",
    "def get_text_after(aligned_index_str : str) -> str:\n",
    "    if aligned_index_str == \"DELETE\":\n",
    "        return \"\"  # Empty string for DELETE\n",
    "    try:\n",
    "        # Convert string like '1, 2, 3' to a list of integers\n",
    "        aligned_indices = list(map(int, aligned_index_str.split(\",\")))\n",
    "    except ValueError:\n",
    "        return None  # If conversion fails, return None\n",
    "\n",
    "    # Find corresponding \"Sentence Content\" in new_draft\n",
    "    text_after = []\n",
    "    for index in aligned_indices:\n",
    "        matching_rows = new_draft_df[new_draft_df[\"Sentence Index\"] == index]\n",
    "        for _, row in matching_rows.iterrows():\n",
    "            text_after.append(row[\"Sentence Content\"])\n",
    "\n",
    "    return \" \".join(text_after)  # Join sentences if there are multiple matches\n",
    "\n",
    "\n",
    "for file in excel_files:\n",
    "        # Read both sheets\n",
    "    old_draft_df = pd.read_excel(file, sheet_name=\"Old Draft\")\n",
    "    new_draft_df = pd.read_excel(file, sheet_name=\"New Draft\")\n",
    "\n",
    "    doc_id = extract_id(os.path.basename(file))  # Extract document ID\n",
    "    # Iterate over the rows in the old draft\n",
    "    for _, old_row in old_draft_df.iterrows():\n",
    "        # Check if \"Identical?\" == 0\n",
    "        if old_row[\"Identical?\"] == 0:\n",
    "            text_before = old_row[\"Sentence Content\"]  # Sentence from old draft\n",
    "            aligned_index = old_row[\"Aligned Index\"]  # Aligned Index in old draft\n",
    "            label = old_row[\"Revision Purpose Level 0\"]\n",
    "            \n",
    "            # Get corresponding \"Text After\" based on Aligned Index\n",
    "            text_after = get_text_after(str(aligned_index))  # Ensure it's a string\n",
    "            \n",
    "            # Add the new row to the new_data list\n",
    "            all_data.append({\n",
    "                \"Text Before\": text_before,\n",
    "                \"Text After\": text_after,\n",
    "                \"Label\": label,\n",
    "                \"Doc Id\": doc_id\n",
    "            })\n",
    "            \n",
    "    for _, new_row in new_draft_df.iterrows():\n",
    "        if str(new_row[\"Aligned Index\"]) == \"ADD\":\n",
    "            text_before = \"\"\n",
    "            label = new_row[\"Revision Purpose Level 0\"]\n",
    "            text_after = new_row[\"Sentence Content\"]\n",
    "\n",
    "            all_data.append({\n",
    "                \"Text Before\": text_before,\n",
    "                \"Text After\": text_after,\n",
    "                \"Label\": label,\n",
    "                \"Doc Id\": doc_id\n",
    "            })\n",
    "# Create the new DataFrame\n",
    "merged_df_23 = pd.DataFrame(all_data)\n",
    "label_counts = merged_df_23[\"Label\"].value_counts()\n",
    "\n",
    "# Filter out rows where the label count is 1\n",
    "merged_df_23 = merged_df_23[merged_df_23['Label'].isin(label_counts[label_counts > 1].index)]\n",
    "\n",
    "# Display or save the new DataFrame\n",
    "# merged_df.to_excel(\"merged_output.xlsx\", index=False)\n",
    "print(merged_df_23.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge by concatenation\n",
    "df = pd.concat([merged_df_12, merged_df_23], ignore_index=True)\n",
    "df.to_csv(\"ArgRewrite_complete.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered = df.groupby(\"Text After\").filter(lambda group: group[\"Label\"].nunique() == 1)\n",
    "df_merged = df_filtered.groupby(\"Text After\", as_index=False).agg({\n",
    "    \"Text Before\": \" \".join,  # Join text_before\n",
    "    \"Doc Id\": \"first\",        # Keep the first author in each group\n",
    "    \"Label\": \"first\"      # Keep the first timestamp in each group\n",
    "})\n",
    "df = df_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gss = GroupShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "train_idxs, test_idxs = next(gss.split(df, groups=df[\"Doc Id\"]))\n",
    "\n",
    "train_df = df.iloc[train_idxs]\n",
    "test_df = df.iloc[test_idxs]\n",
    "\n",
    "print(\"Training set size:\", len(train_df))\n",
    "print(\"Test set size:\", len(test_df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_percentages = df[\"Label\"].value_counts(normalize=True) * 100  # Convert to percentage\n",
    "print(label_percentages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_percentages = train_df[\"Label\"].value_counts(normalize=True) * 100  # Convert to percentage\n",
    "print(label_percentages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_percentages = test_df[\"Label\"].value_counts(normalize=True) * 100  # Convert to percentage\n",
    "print(label_percentages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Essai 1 : Few-shot Cot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assistant_first = client.beta.assistants.create(\n",
    "  name=\"ArgRewrite-try-1\",\n",
    "  instructions=\"\"\"You are evaluating text revisions by comparing different states of a text (before and after a revision).\n",
    "\n",
    "**Prompt students answered:**  \n",
    "Write an op-ed for the *Pittsburgh City Paper* on whether self-driving cars benefit society. Briefly outline their advantages and disadvantages, then take a stance—either for or against—supporting it with strong evidence, explanations, and a counter-argument. Ensure clarity, precision, and proper organization.\n",
    "\n",
    "**Classification Task:**  \n",
    "Provide a step-by-step reasoning (Chain of Thought) before concluding with one of the following categories:\n",
    "\n",
    "- **Word-Usage/Clarity**: Changes to improve clarity or word choice without altering the meaning of the content.\n",
    "   - Example:  \n",
    "      - Before: \"Technology remains to be the nourishment of civilizations.\"  \n",
    "      - After: \"Technology remains to be the backbone of civilizations.\"\n",
    "\n",
    "- **Conventions/Grammar/Spelling*: Corrections of spelling and grammatical errors.\n",
    "- Example:  \n",
    "      - Before: \"Big corporations stick together and attack on one another.\"  \n",
    "      - After: \"Big corporations stick together and attack one another.\"\n",
    "\n",
    "- **General Content Development**: Significant additions, deletions, or rewording of content without a clear argumentative function.\n",
    "- Example:  \n",
    "      - Before: \"Self-driving cars will one day be the same.\"  \n",
    "      - After: \"Self-driving cars will one day be the same - once thought impossible, but eventually taken for granted.\"\n",
    "\n",
    "- **Precision**: Edits that adjust the specificity of a sentence, influencing its level of detail.\n",
    "- Example:  \n",
    "      - Before: \"However, the pros outweigh the cons.\"  \n",
    "      - After: \"However, the pros of self-driving cars outweigh the cons.\"\n",
    "\n",
    "- **Organization**: Structural modifications, such as rearranging sentences by splitting them or reunite them.\n",
    "- Example:  \n",
    "      - Before: \"In my opinion, I support self-driving cars. The technology will have positive impacts on the society.\"  \n",
    "      - After: \"In my opinion, I support self-driving cars because the technology will have positive impacts on the society.\"\n",
    "\n",
    "- **Warrant/Reasoning/Backing**: Changes in explanations or logical support for a claim.\n",
    "- Example:  \n",
    "      - Before: \"By reducing traffic, gas expenses would be lower.\"  \n",
    "      - After: \"Self-driving cars will have the ability to coordinate with each other to prevent and reduce traffic, which means gas expenses would be lower.\"\n",
    "\n",
    "- **Evidence**: Additions or modifications of factual information to support an argument.\n",
    "- Example:  \n",
    "      - Before: \"A lot of expensive machinery will be needed to make a self-driving car.\"  \n",
    "      - After: \"A lot of expensive machinery, like sensors and cameras, will be needed to make a self-driving car.\"\n",
    "\n",
    "\n",
    "- **Claims/Ideas**: Edits that modify (add or delete) a main claim or idea of the essay.\n",
    "- Example:  \n",
    "      - Before: \"Overall, self-driving cars are infiltrating our society at a rather rapid rate.\"  \n",
    "      - After: \"Overall, self-driving cars are immigrating into our society with many benefits.\"\n",
    "\n",
    "- **Rebuttal/Reservation**: Edits related to refuting an opposing argument.\n",
    "- Example:  \n",
    "      - Before: \"Self driving cars are the subject of much scrutiny.\"  \n",
    "      - After: \"Self driving cars are not perfect yet, and there are still many issues to be worked out.\"\n",
    "\n",
    "\n",
    "**Guidelines for Ambiguous Cases:**  \n",
    "If multiple revision purposes exist, follow these rules:  \n",
    "\n",
    "- **Claim/Ideas vs. Warrant/Reasoning/Backing**: A main claim is \"Claims/Ideas,\" while supporting arguments are \"Warrant/Reasoning/Backing.\"  \n",
    "- **General Content vs. Warrant/Reasoning/Backing**: If it expresses the author's stance, classify as \"Warrant/Reasoning/Backing\"; otherwise, as \"General Content.\"  \n",
    "- **Evidence vs. Warrant/Reasoning/Backing**: Factual support (e.g., citations, examples) is \"Evidence\"; otherwise, it's \"Warrant/Reasoning/Backing.\"  \n",
    "- **Conventions/Grammar/Spelling vs. Word-Usage/Clarity**: If only grammar/spelling is corrected, use \"Conventions/Grammar/Spelling\"; otherwise, use \"Word-Usage/Clarity.\"  \n",
    "- **Precision vs. Word-Usage/Clarity**: If a change affects meaning and specificity, use \"Precision\"; otherwise, \"Word-Usage/Clarity.\"  \n",
    "- **Claim/Idea vs. Word-Usage/Clarity**: If a change impacts the essay’s main argument, classify as \"Claim/Ideas.\"  \n",
    "- **Organization vs. General Content Development**: Reordering sentences is \"Organization\"; significant content changes are \"General Content.\"  \n",
    "\n",
    "You may consider previous text versions from the same essay for context.\n",
    " \n",
    "**Output Format:**\n",
    "Your response **must** follow this exact JSON format:  \n",
    "```json\n",
    "{\n",
    "      \"reasoning\": \"<Step-by-step explanation of the classification>\",\n",
    "      \"classification\": \"category chosen\"\n",
    "}\"\"\",\n",
    "  tools=[],\n",
    "  model=\"gpt-4o\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Essai 2 - Multiple steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assistant_first = client.beta.assistants.create(\n",
    "  name=\"ArgRewrite-try-2-step1\",\n",
    "  instructions=\"\"\"You are evaluating text revisions by comparing different states of a text (before and after a revision).\n",
    "\n",
    "**Contextual Awareness:**  \n",
    "You are evaluating a *sequence* of revisions within the same essay. It is essential to consider earlier parts of the essay to accurately determine the purpose of a revision. Always reason based on the surrounding context and how the revision fits into the overall argumentative structure.\n",
    "\n",
    "\n",
    "**Prompt students answered:**  \n",
    "Write an op-ed for the *Pittsburgh City Paper* on whether self-driving cars benefit society. Briefly outline their advantages and disadvantages, then take a stance—either for or against—supporting it with strong evidence, explanations, and a counter-argument. Ensure clarity, precision, and proper organization.\n",
    "\n",
    "\n",
    "**Classification Task:**  \n",
    "Provide a step-by-step reasoning (Chain of Thought) before concluding with one of the following categories for each text given as input:\n",
    "\n",
    "- **Surface changes**: Edits that concerns surface changes like organization, spelling or grammar correction or clarity improvements that do not change the deep meaning of the text.\n",
    "- Example:  \n",
    "      - Before: \"Technology is the nourishment of civilizations.\"  \n",
    "      - After: \"Technology is the backbone of civilizations.\" \n",
    "\n",
    "- Example:  \n",
    "      - Before: \"Big corporations stick together and attack on one another.\"  \n",
    "      - After: \"Big corporations stick together and attack one another.\"\n",
    "\n",
    "- **Content changes**: Edits that concerns meaning changes directly linked to the argumentation or just general content development.\n",
    "- Example:  \n",
    "      - Before: \"Self-driving cars are helpful.\"\n",
    "      - After: \"Self-driving cars reduce accidents by 90%.\"\n",
    "\n",
    "- Example:  \n",
    "      - Before: \"Overall, self-driving cars are infiltrating our society at a rather rapid rate.\"  \n",
    "      - After: \"Overall, self-driving cars are immigrating into our society with many benefits.\"\n",
    "\n",
    "\n",
    "\n",
    "You **must** consider previous messages in the thread as part of your context.\n",
    "\n",
    "**Output Format:**\n",
    "Your response **must** follow this exact JSON format:  \n",
    "```json\n",
    "{\n",
    "      \"reasoning\": \"<Step-by-step explanation of the classification>\",\n",
    "      \"classification\": \"category chosen\"\n",
    "}\"\"\",\n",
    "  tools=[],\n",
    "  model=\"gpt-4o\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assistant_first = client.beta.assistants.create(\n",
    "  name=\"ArgRewrite-try-2-step2-content\",\n",
    "  instructions=\"\"\"You are evaluating text revisions by comparing different states of a text (before and after a revision). The considered revision has been classified as having an impact on the meaning of the text. You should now subclassify it.\n",
    "\n",
    "**Contextual Awareness:**  \n",
    "You are evaluating a *sequence* of revisions within the same essay. It is essential to consider earlier parts of the essay to accurately determine the purpose of a revision. Always reason based on the surrounding context and how the revision fits into the overall argumentative structure.\n",
    "\n",
    "\n",
    "**Prompt students answered:**  \n",
    "Write an op-ed for the *Pittsburgh City Paper* on whether self-driving cars benefit society. Briefly outline their advantages and disadvantages, then take a stance—either for or against—supporting it with strong evidence, explanations, and a counter-argument. Ensure clarity, precision, and proper organization.\n",
    "\n",
    "\n",
    "**Classification Task:**  \n",
    "Provide a step-by-step reasoning (Chain of Thought) before concluding with one of the following categories:\n",
    "\n",
    "\n",
    "- **General Content Development**: Significant additions, deletions, or rewording of content without a clear argumentative function.\n",
    "- Example:  \n",
    "      - Before: \"Self-driving cars will one day be the same.\"  \n",
    "      - After: \"Self-driving cars will one day be the same - once thought impossible, but eventually taken for granted.\"\n",
    "\n",
    "\n",
    "- **Precision**: Edits that add or reduce quantifiable, factual, or definitional detail, affecting how specific a statement is and altering its meaning. Use \"Precision\" only when an edit introduces or removes specific factual detail (e.g., names, quantities, types). If a change slightly broadens or narrows specificity without introducing or removing factual detail, classify it as \"Word-Usage/Clarity.\"\n",
    "- Example:  \n",
    "      - Before: \"Self-driving cars are helpful.\"\n",
    "      - After: \"Self-driving cars reduce accidents by 90%.\"\n",
    "\n",
    "- **Warrant/Reasoning/Backing**: Changes in explanations or logical support for a claim, related to the prompt students answered to.\n",
    "- Example:  \n",
    "      - Before: \"By reducing traffic, gas expenses would be lower.\"  \n",
    "      - After: \"Self-driving cars will have the ability to coordinate with each other to prevent and reduce traffic, which means gas expenses would be lower.\"\n",
    "\n",
    "- **Evidence**: Additions or modifications of factual information to support an argument that is link to the prompt students answered to.\n",
    "- Example:  \n",
    "      - Before: \"A lot of expensive machinery will be needed to make a self-driving car.\"  \n",
    "      - After: \"A lot of expensive machinery, like sensors and cameras, will be needed to make a self-driving car.\"\n",
    "\n",
    "\n",
    "- **Claims/Ideas**: Edits that modify (add or delete) a main claim or idea of the essay related to the prompt students answered to. Make sure the revision is no related to a previous claim before choosing this type.\n",
    "- Example:  \n",
    "      - Before: \"Overall, self-driving cars are infiltrating our society at a rather rapid rate.\"  \n",
    "      - After: \"Overall, self-driving cars are immigrating into our society with many benefits.\"\n",
    "\n",
    "- **Rebuttal/Reservation**: Edits related to refuting an opposing argument.\n",
    "- Example:  \n",
    "      - Before: \"Self driving cars are the subject of much scrutiny.\"  \n",
    "      - After: \"Self driving cars are not perfect yet, and there are still many issues to be worked out.\"\n",
    "\n",
    "\n",
    "**Guidelines for Ambiguous Cases:**  \n",
    "If you hesitate between multiple revision purposes, follow these rules:  \n",
    "\n",
    "- **Precision vs. Word-Usage/Clarity**: Use \"Precision\" only if the revision introduces or removes **factual**, **technical**, or **quantifiable** detail. If the change improves clarity or adds rhetorical nuance (e.g., “completely,”), use \"Word-Usage/Clarity.\"\n",
    "\n",
    "      # Ambiguous case:\n",
    "\n",
    "      Before: \"Self-driving cars are the future.\"\n",
    "      After: \"Self-driving vehicles represent the future.\"\n",
    "\n",
    "      → This is **Word-Usage/Clarity**, because it swaps terms for clarity without adding detail.\n",
    "\n",
    "- **Claim/Ideas vs. Warrant/Reasoning/Backing**: A main claim is \"Claims/Ideas,\" while supporting arguments to an already written claim are \"Warrant/Reasoning/Backing.\"  \n",
    "- **General Content vs. Warrant/Reasoning/Backing**: If it expresses the author's stance, classify as \"Warrant/Reasoning/Backing\"; otherwise, as \"General Content.\"  \n",
    "- **Evidence vs. Warrant/Reasoning/Backing**: Factual support (e.g., citations, examples) is \"Evidence\"; otherwise, it's \"Warrant/Reasoning/Backing.\"   \n",
    "- **Organization vs. General Content Development**: Reordering sentences is \"Organization\"; significant content changes are \"General Content.\"  \n",
    "\n",
    "You **must** consider previous messages in the thread as part of your context. Many revisions cannot be accurately classified in isolation especially to see the links between the claims, evidences and reasoning categories.\n",
    "\n",
    "**Output Format:**\n",
    "Your response **must** follow this exact JSON format:  \n",
    "```json\n",
    "{\n",
    "      \"reasoning\": \"<Step-by-step explanation of the classification>\",\n",
    "      \"classification\": \"category chosen\"\n",
    "}\"\"\",\n",
    "  tools=[],\n",
    "  model=\"gpt-4o\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assistant_first = client.beta.assistants.create(\n",
    "  name=\"ArgRewrite-try-2-step2-surface\",\n",
    "  instructions=\"\"\"You are evaluating text revisions by comparing different states of a text (before and after a revision). The considered revision has been classified as being a surface revision. You should now subclassify it.\n",
    "\n",
    "**Contextual Awareness:**  \n",
    "You are evaluating a *sequence* of revisions within the same essay. It is essential to consider earlier parts of the essay to accurately determine the purpose of a revision. Always reason based on the surrounding context and how the revision fits into the overall argumentative structure.\n",
    "\n",
    "\n",
    "**Prompt students answered:**  \n",
    "Write an op-ed for the *Pittsburgh City Paper* on whether self-driving cars benefit society. Briefly outline their advantages and disadvantages, then take a stance—either for or against—supporting it with strong evidence, explanations, and a counter-argument. Ensure clarity, precision, and proper organization.\n",
    "\n",
    "\n",
    "For each revision of the text do this classification task : \n",
    "**Classification Task:**  \n",
    "Provide a step-by-step reasoning (Chain of Thought) before concluding with one of the following categories for each text given as input:\n",
    "\n",
    "- **Word-Usage/Clarity**: Edits that improve fluency, clarity, or word choice, without changing factual content or specificity. Use \"Word-Usage/Clarity\" for fluency improvements, synonyms, or idiomatic rewrites that preserve meaning.\n",
    "- Example:  \n",
    "      - Before: \"Technology is the nourishment of civilizations.\"  \n",
    "      - After: \"Technology is the backbone of civilizations.\" \n",
    "\n",
    "- **Conventions/Grammar/Spelling**: Corrections of spelling and grammatical errors or convent.\n",
    "- Example:  \n",
    "      - Before: \"Big corporations stick together and attack on one another.\"  \n",
    "      - After: \"Big corporations stick together and attack one another.\"\n",
    "\n",
    "- **Organization**: Structural modifications, such as rearranging sentences by splitting them or reunite them.\n",
    "- Example:  \n",
    "      - Before: \"In my opinion, I support self-driving cars. The technology will have positive impacts on the society.\"  \n",
    "      - After: \"In my opinion, I support self-driving cars because the technology will have positive impacts on the society.\"\n",
    "\n",
    "\n",
    "**Guidelines for Ambiguous Cases:**  \n",
    "If you hesitate between multiple revision purposes, follow these rules:  \n",
    "\n",
    "- **Conventions/Grammar/Spelling vs. Word-Usage/Clarity**: If only grammar/spelling is corrected, use \"Conventions/Grammar/Spelling\"; otherwise, use \"Word-Usage/Clarity.\"  \n",
    "\n",
    "You **must** consider previous messages in the thread as part of your context.\n",
    "\n",
    "**Output Format:**\n",
    "Your response **must** follow this exact JSON format:  \n",
    "```json\n",
    "{\n",
    "       \"reasoning\": \"<Step-by-step explanation of the classification>\",\n",
    "      \"classification\": \"category chosen\"\n",
    "}\"\"\",\n",
    "  tools=[],\n",
    "  model=\"gpt-4o\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Essai 3 : Reverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assistant_first = client.beta.assistants.create(\n",
    "  name=\"ArgRewrite-try-3\",\n",
    "  instructions=\"\"\"You are evaluating text revisions by comparing different states of a text (before and after a revision).\n",
    "\n",
    "**Contextual Awareness:**  \n",
    "You are evaluating a *sequence* of revisions within the same essay. It is essential to consider earlier parts of the essay to accurately determine the purpose of a revision. Always reason based on the surrounding context and how the revision fits into the overall argumentative structure.\n",
    "\n",
    "\n",
    "**Prompt students answered:**  \n",
    "Write an op-ed for the *Pittsburgh City Paper* on whether self-driving cars benefit society. Briefly outline their advantages and disadvantages, then take a stance—either for or against—supporting it with strong evidence, explanations, and a counter-argument. Ensure clarity, precision, and proper organization.\n",
    "\n",
    "\n",
    "For each revision of the text do this classification task : \n",
    "**Classification Task:**  \n",
    "Provide a step-by-step reasoning (Chain of Thought) before concluding with one of the following categories for each text given as input:\n",
    "\n",
    "- **Word-Usage/Clarity**: Edits that improve fluency, clarity, or word choice, without changing factual content or specificity. Use \"Word-Usage/Clarity\" for fluency improvements, synonyms, or idiomatic rewrites that preserve meaning.\n",
    "- Example:  \n",
    "      - Before: \"Technology is the nourishment of civilizations.\"  \n",
    "      - After: \"Technology is the backbone of civilizations.\" \n",
    "\n",
    "- **Conventions/Grammar/Spelling**: Corrections of spelling and grammatical errors or convent.\n",
    "- Example:  \n",
    "      - Before: \"Big corporations stick together and attack on one another.\"  \n",
    "      - After: \"Big corporations stick together and attack one another.\"\n",
    "\n",
    "- **General Content Development**: Significant additions, deletions, or rewording of content without a clear argumentative function.\n",
    "- Example:  \n",
    "      - Before: \"Self-driving cars will one day be the same.\"  \n",
    "      - After: \"Self-driving cars will one day be the same - once thought impossible, but eventually taken for granted.\"\n",
    "\n",
    "\n",
    "- **Precision**: Edits that add or reduce quantifiable, factual, or definitional detail, affecting how specific a statement is and altering its meaning. Use \"Precision\" only when an edit introduces or removes specific factual detail (e.g., names, quantities, types). If a change slightly broadens or narrows specificity without introducing or removing factual detail, classify it as \"Word-Usage/Clarity.\"\n",
    "- Example:  \n",
    "      - Before: \"Self-driving cars are helpful.\"\n",
    "      - After: \"Self-driving cars reduce accidents by 90%.\"\n",
    "Use \"Word-Usage/Clarity\" when edits add stylistic or rhetorical specificity, such as clarifying tone or phrasing, unless the edit introduces concrete facts, types, quantities, or definitions.\n",
    "- Example:  \n",
    "      - Before: \"make a decision\"  \n",
    "      - After: \"make a human judgment decision\"\n",
    "\n",
    "      → This is **Word-Usage/Clarity**. While the revision adds a descriptive qualifier, it does not introduce factual or technical specificity.\n",
    "\n",
    "\n",
    "- **Organization**: Structural modifications, such as rearranging sentences by splitting them or reunite them.\n",
    "- Example:  \n",
    "      - Before: \"In my opinion, I support self-driving cars. The technology will have positive impacts on the society.\"  \n",
    "      - After: \"In my opinion, I support self-driving cars because the technology will have positive impacts on the society.\"\n",
    "\n",
    "- **Warrant/Reasoning/Backing**: Changes in explanations or logical support for a claim, related to the prompt students answered to.\n",
    "- Example:  \n",
    "      - Before: \"By reducing traffic, gas expenses would be lower.\"  \n",
    "      - After: \"Self-driving cars will have the ability to coordinate with each other to prevent and reduce traffic, which means gas expenses would be lower.\"\n",
    "\n",
    "- **Evidence**: Additions or modifications of factual information to support an argument that is link to the prompt students answered to.\n",
    "- Example:  \n",
    "      - Before: \"A lot of expensive machinery will be needed to make a self-driving car.\"  \n",
    "      - After: \"A lot of expensive machinery, like sensors and cameras, will be needed to make a self-driving car.\"\n",
    "\n",
    "\n",
    "- **Claims/Ideas**: Edits that modify (add or delete) a major claim or idea of the essay related to the prompt students answered to. Make sure the revision is not related to a previous claim before choosing this type, if it is choose Warrant/Reasoning/Backing instead.\n",
    "- Example:  \n",
    "      - Before: \"Overall, self-driving cars are infiltrating our society at a rather rapid rate.\"  \n",
    "      - After: \"Overall, self-driving cars are immigrating into our society with many benefits.\"\n",
    "\n",
    "- **Rebuttal/Reservation**: Edits related to refuting an opposing argument.\n",
    "- Example:  \n",
    "      - Before: \"Self driving cars are the subject of much scrutiny.\"  \n",
    "      - After: \"Self driving cars are not perfect yet, and there are still many issues to be worked out.\"\n",
    "\n",
    "\n",
    "**Guidelines for Ambiguous Cases:**  \n",
    "If you hesitate between multiple revision purposes, follow these rules:  \n",
    "\n",
    "- **Precision vs. Word-Usage/Clarity**: Use \"Precision\" only if the revision introduces or removes **factual**, **technical**, or **quantifiable** detail. If the change improves clarity or adds rhetorical nuance (e.g., “completely,” “human judgment”), use \"Word-Usage/Clarity.\"\n",
    "\n",
    "      # Ambiguous case:\n",
    "\n",
    "      Before: \"Self-driving cars are the future.\"\n",
    "      After: \"Self-driving vehicles represent the future.\"\n",
    "\n",
    "      → This is **Word-Usage/Clarity**, because it swaps terms for clarity without adding detail.\n",
    "\n",
    "- **Claim/Ideas vs. Warrant/Reasoning/Backing**: A main claim is \"Claims/Ideas,\" while supporting arguments to an already written claim are \"Warrant/Reasoning/Backing.\"  \n",
    "- **General Content vs. Warrant/Reasoning/Backing**: If it expresses the author's stance, classify as \"Warrant/Reasoning/Backing\"; otherwise, as \"General Content.\"  \n",
    "- **Evidence vs. Warrant/Reasoning/Backing**: Factual support (e.g., citations, examples) is \"Evidence\"; otherwise, it's \"Warrant/Reasoning/Backing.\"  \n",
    "- **Conventions/Grammar/Spelling vs. Word-Usage/Clarity**: If only grammar/spelling is corrected, use \"Conventions/Grammar/Spelling\"; otherwise, use \"Word-Usage/Clarity.\"  \n",
    "- **Claim/Idea vs. Word-Usage/Clarity**: If a change impacts the essay’s main argument, classify as \"Claim/Ideas.\"  \n",
    "- **Organization vs. General Content Development**: Reordering sentences is \"Organization\"; significant content changes are \"General Content.\"  \n",
    "\n",
    "You **must** consider previous messages in the thread as part of your context. Many revisions cannot be accurately classified in isolation especially to see the links between the claims, evidences and reasoning categories.\n",
    "\n",
    "**Output Format:**\n",
    "Your response **must** follow this exact JSON format:  \n",
    "```json\n",
    "{\n",
    "      \"classification\": \"category chosen\",\n",
    "      \"reasoning\": \"<Step-by-step explanation of the classification>\"\n",
    "      \n",
    "}\"\"\",\n",
    "  tools=[],\n",
    "  model=\"gpt-4o\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict and evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all assistants\n",
    "assistants = client.beta.assistants.list()\n",
    "\n",
    "# Print their IDs\n",
    "for assistant in assistants.data:\n",
    "    print(f\"Name: {assistant.name}, ID: {assistant.id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assistant_id = \"your_assistant_id\"\n",
    "# or in case of multiple steps\n",
    "assistant_id_step1 = \"your_assistant_id\"\n",
    "assistant_id_step2_content = \"your_assistant_id\"\n",
    "assistant_id_step2_surface = \"your_assistant_id\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def classify_with_assistants_full_text(text_before, text_after, thread, previously_classified):\n",
    "    while True:\n",
    "        runs = client.beta.threads.runs.list(thread_id=thread.id)\n",
    "        active_runs = [r for r in runs.data if r.status in [\"queued\", \"in_progress\"]]\n",
    "        \n",
    "        if not active_runs:\n",
    "            break  # No active runs, proceed\n",
    "        print(\"Waiting for active run to complete...\")\n",
    "        time.sleep(2)  # Wait and check again\n",
    "\n",
    "    # Step 1: Request Meaning Classification Assistant\n",
    "    message = client.beta.threads.messages.create(\n",
    "        thread_id=thread.id,\n",
    "        role=\"user\",\n",
    "        content=f\"Here is previously classified text belonging to the same student's answer : {previously_classified}. Classify this revision:\\nBefore: {text_before}\\nAfter: {text_after}\\nReturn JSON output.\"\n",
    "    )\n",
    "\n",
    "    # Run first assistant\n",
    "    run = client.beta.threads.runs.create(thread_id=thread.id, assistant_id=assistant_id)\n",
    "\n",
    "    # Wait for completion\n",
    "    while run.status in [\"queued\", \"in_progress\"]:\n",
    "        time.sleep(2)\n",
    "        run = client.beta.threads.runs.retrieve(thread_id=thread.id, run_id=run.id)\n",
    "\n",
    "    # Retrieve response\n",
    "    messages = client.beta.threads.messages.list(thread_id=thread.id)\n",
    "    print(messages)\n",
    "    response_text = messages.data[0].content[0].text.value\n",
    "    print(response_text)\n",
    "\n",
    "    try:\n",
    "        clean_response_text = response_text.replace(\"```json\", \"\").replace(\"```\", \"\").strip()\n",
    "        response = json.loads(clean_response_text)\n",
    "        category = response['classification']\n",
    "        reasoning_1 = response['reasoning']\n",
    "        \n",
    "    except json.JSONDecodeError:\n",
    "        print(\"Error parsing first response:\", response_text)\n",
    "        exit()\n",
    "\n",
    "\n",
    "    print(\"Step 1 Classification:\", category)\n",
    "\n",
    "    \n",
    "    return {\"classification\": category, \"reasoning\": reasoning_1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def classify_with_assistants_multiple_steps(text_before, text_after, thread_main, thread_content, thread_surface, previously_classified):\n",
    "    while True:\n",
    "        runs = client.beta.threads.runs.list(thread_id=thread_main.id)\n",
    "        active_runs = [r for r in runs.data if r.status in [\"queued\", \"in_progress\"]]\n",
    "        \n",
    "        if not active_runs:\n",
    "            break  # No active runs, proceed\n",
    "        print(\"Waiting for active run to complete...\")\n",
    "        time.sleep(2)  # Wait and check again\n",
    "\n",
    "    # Step 1: Request Meaning Classification Assistant\n",
    "    message = client.beta.threads.messages.create(\n",
    "        thread_id=thread_main.id,\n",
    "        role=\"user\",\n",
    "        content=f\"Classify this revision:\\nBefore: {text_before}\\nAfter: {text_after}\\nReturn JSON output.\"\n",
    "    )\n",
    "\n",
    "    # Run first assistant\n",
    "    run = client.beta.threads.runs.create(thread_id=thread_main.id, assistant_id=assistant_id_step1)\n",
    "\n",
    "    # Wait for completion\n",
    "    while run.status in [\"queued\", \"in_progress\"]:\n",
    "        time.sleep(2)\n",
    "        run = client.beta.threads.runs.retrieve(thread_id=thread_main.id, run_id=run.id)\n",
    "\n",
    "    # Retrieve response\n",
    "    messages = client.beta.threads.messages.list(thread_id=thread_main.id)\n",
    "    print(messages)\n",
    "    response_text = messages.data[0].content[0].text.value\n",
    "    print(response_text)\n",
    "\n",
    "    try:\n",
    "        clean_response_text = response_text.replace(\"```json\", \"\").replace(\"```\", \"\").strip()\n",
    "        response = json.loads(clean_response_text)\n",
    "        main_category = response['classification']\n",
    "        reasoning_1 = response['reasoning']\n",
    "        \n",
    "    except json.JSONDecodeError:\n",
    "        print(\"Error parsing first response:\", response_text)\n",
    "        exit()\n",
    "\n",
    "\n",
    "    print(\"Step 1 Classification:\", main_category)\n",
    "\n",
    "    if main_category==\"Surface changes\" or main_category == \"surface changes\":\n",
    "        while True:\n",
    "            runs = client.beta.threads.runs.list(thread_id=thread_surface.id)\n",
    "            active_runs = [r for r in runs.data if r.status in [\"queued\", \"in_progress\"]]\n",
    "            \n",
    "            if not active_runs:\n",
    "                break  # No active runs, proceed\n",
    "            print(\"Waiting for active run to complete...\")\n",
    "            time.sleep(2)  # Wait and check again\n",
    "\n",
    "        # Step 1: Request Meaning Classification Assistant\n",
    "        message = client.beta.threads.messages.create(\n",
    "            thread_id=thread_surface.id,\n",
    "            role=\"user\",\n",
    "            content=f\"Here is previously classified text belonging to the same student's answer : {previously_classified}. Classify this revision:\\nBefore: {text_before}\\nAfter: {text_after}\\nReturn JSON output.\"\n",
    "        )\n",
    "\n",
    "        # Run first assistant\n",
    "        run = client.beta.threads.runs.create(thread_id=thread_surface.id, assistant_id=assistant_id_step2_surface)\n",
    "\n",
    "        # Wait for completion\n",
    "        while run.status in [\"queued\", \"in_progress\"]:\n",
    "            time.sleep(2)\n",
    "            run = client.beta.threads.runs.retrieve(thread_id=thread_surface.id, run_id=run.id)\n",
    "\n",
    "        # Retrieve response\n",
    "        messages = client.beta.threads.messages.list(thread_id=thread_surface.id)\n",
    "        print(messages)\n",
    "        response_text = messages.data[0].content[0].text.value\n",
    "        print(response_text)\n",
    "\n",
    "        try:\n",
    "            clean_response_text = response_text.replace(\"```json\", \"\").replace(\"```\", \"\").strip()\n",
    "            response = json.loads(clean_response_text)\n",
    "            category = response['classification']\n",
    "            reasoning_2 = response['reasoning']\n",
    "            \n",
    "        except json.JSONDecodeError:\n",
    "            print(\"Error parsing first response:\", response_text)\n",
    "            exit()\n",
    "\n",
    "\n",
    "    elif main_category==\"Content changes\" or main_category==\"content changes\":\n",
    "        while True:\n",
    "            runs = client.beta.threads.runs.list(thread_id=thread_content.id)\n",
    "            active_runs = [r for r in runs.data if r.status in [\"queued\", \"in_progress\"]]\n",
    "            \n",
    "            if not active_runs:\n",
    "                break  # No active runs, proceed\n",
    "            print(\"Waiting for active run to complete...\")\n",
    "            time.sleep(2)  # Wait and check again\n",
    "\n",
    "        # Step 1: Request Meaning Classification Assistant\n",
    "        message = client.beta.threads.messages.create(\n",
    "            thread_id=thread_content.id,\n",
    "            role=\"user\",\n",
    "            content=f\"Here is previously classified text belonging to the same student's answer : {previously_classified}. Classify this revision:\\nBefore: {text_before}\\nAfter: {text_after}\\nReturn JSON output.\"\n",
    "        )\n",
    "\n",
    "        # Run first assistant\n",
    "        run = client.beta.threads.runs.create(thread_id=thread_content.id, assistant_id=assistant_id_step2_content)\n",
    "\n",
    "        # Wait for completion\n",
    "        while run.status in [\"queued\", \"in_progress\"]:\n",
    "            time.sleep(2)\n",
    "            run = client.beta.threads.runs.retrieve(thread_id=thread_content.id, run_id=run.id)\n",
    "\n",
    "        # Retrieve response\n",
    "        messages = client.beta.threads.messages.list(thread_id=thread_content.id)\n",
    "        print(messages)\n",
    "        response_text = messages.data[0].content[0].text.value\n",
    "        print(response_text)\n",
    "\n",
    "        try:\n",
    "            clean_response_text = response_text.replace(\"```json\", \"\").replace(\"```\", \"\").strip()\n",
    "            response = json.loads(clean_response_text)\n",
    "            category = response['classification']\n",
    "            reasoning_2 = response['reasoning']\n",
    "            \n",
    "        except json.JSONDecodeError:\n",
    "            print(\"Error parsing first response:\", response_text)\n",
    "            exit()\n",
    "\n",
    "    else:\n",
    "        print(\"ERROR\")\n",
    "        exit()\n",
    "    \n",
    "    return {\"classification\": category, \"reasoning_step1\": reasoning_1, \"reasoning_step2\": reasoning_2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(dataf, save_path=\"path_to_save_predictions.csv\"):\n",
    "    # Load existing predictions if the file exists\n",
    "    if os.path.exists(save_path):\n",
    "        existing_df = pd.read_csv(save_path, index_col=0)\n",
    "        completed_indices = set(existing_df.index)  # Indices of already processed rows\n",
    "        # Filter the original dataframe to only include rows that have not been processed yet\n",
    "        dataf = dataf[~dataf.index.isin(completed_indices)]\n",
    "    else:\n",
    "        completed_indices = set()\n",
    "\n",
    "    # Process the remaining rows\n",
    "    prev_text_id = -1\n",
    "    previously_classified = \"\"\n",
    "    for index, row in dataf.iterrows():\n",
    "        try:\n",
    "            if row[\"Doc Id\"]!= prev_text_id:\n",
    "                thread_main = client.beta.threads.create()\n",
    "                thread_content = client.beta.threads.create()\n",
    "                thread_surface = client.beta.threads.create()\n",
    "                prev_text_id = row[\"Doc Id\"]\n",
    "                previously_classified = \"\"\n",
    "\n",
    "            #adapt to not multiple steps model if needed\n",
    "            prediction = classify_with_assistants_multiple_steps(row['Text Before'], row['Text After'], thread_main, thread_content, thread_surface, previously_classified)\n",
    "            previously_classified+= f\"\"\"Previous text : {row['Text After']}, Label given : {prediction['classification']};\\n\"\"\"\n",
    "            dataf.loc[index, \"prediction\"] = prediction[\"classification\"]\n",
    "            if \"reasoning_step1\" in prediction:\n",
    "                dataf.loc[index, \"reasoning_step1\"] = prediction[\"reasoning_step1\"]\n",
    "            if \"reasoning_step2\" in prediction:\n",
    "                dataf.loc[index, \"reasoning_step2\"] = prediction[\"reasoning_step2\"]\n",
    "            dataf.loc[[index]].to_csv(save_path, mode=\"a\", header=not os.path.exists(save_path), index=True)\n",
    "\n",
    "            # Mark this index as completed\n",
    "            completed_indices.add(index)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error at index {index}: {e}\")\n",
    "            break  # Stop execution if needed\n",
    "\n",
    "    return dataf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simplify_labels(y):\n",
    "    y_simplified = []\n",
    "    surface_labels = [\n",
    "    \"word-usage/clarity\",\n",
    "    \"conventions/grammar/spelling\",\n",
    "    \"organization\"        \n",
    "    ]\n",
    "    content_labels = [\n",
    "    \"general content development\",\n",
    "    \"precision\",\n",
    "    \"warrant/reasoning/backing\",\n",
    "    \"evidence\",\n",
    "    \"claims/ideas\",\n",
    "    \"rebuttal/reservation\"\n",
    "    ]\n",
    "    for label in y:\n",
    "        if label in surface_labels:\n",
    "            y_simplified.append(\"surface\")\n",
    "        elif label in content_labels:\n",
    "            y_simplified.append(\"content\")\n",
    "        else:\n",
    "            print(\"issue\")\n",
    "            print(label)\n",
    "            y_simplified.append(\"none\")\n",
    "    return y_simplified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapping_categories(df):\n",
    "    # Define the mapping\n",
    "    mapping = {\n",
    "        \"Word-Usage/Clarity\": \"Clarity\",\n",
    "        \"Conventions/Grammar/Spelling\": \"Grammar\",\n",
    "        \"Evidence\": \"Fact/Evidence\",\n",
    "        \"Claims/Ideas\": \"Claim\",\n",
    "        \"Claim/Ideas\": \"Claim\",\n",
    "        \"Warrant/Reasoning/Backing\": \"Claim\",\n",
    "        \"Rebuttal/Reservation\": \"Claim\",\n",
    "        \"Organization\": \"Clarity\",\n",
    "        \"Precision\": \"Other\",\n",
    "        \"General Content Development\": \"Other\"\n",
    "    }\n",
    "\n",
    "    # Check for unmapped values in both columns\n",
    "    for col in [\"Label\", \"prediction\"]:\n",
    "        unmatched = set(df[col].unique()) - set(mapping.keys())\n",
    "        if unmatched:\n",
    "            raise ValueError(f\"Unmatched values in column '{col}': {unmatched}\")\n",
    "\n",
    "    # Apply the mapping\n",
    "    df[\"Label\"] = df[\"Label\"].map(mapping)\n",
    "    df[\"prediction\"] = df[\"prediction\"].map(mapping)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(results):\n",
    "    results[\"prediction\"] = results[\"prediction\"].str.lower()\n",
    "    results[\"Label\"] = results[\"Label\"].str.lower()\n",
    "    \n",
    "    y_true = results[\"Label\"].to_numpy()\n",
    "    y_pred = results[\"prediction\"].to_numpy()\n",
    "\n",
    "\n",
    "    class_labels = [\n",
    "    \"word-usage/clarity\",\n",
    "    \"conventions/grammar/spelling\",\n",
    "    \"general content development\",\n",
    "    \"precision\",\n",
    "    \"organization\",\n",
    "    \"warrant/reasoning/backing\",\n",
    "    \"evidence\",\n",
    "    \"claims/ideas\",\n",
    "    \"rebuttal/reservation\"\n",
    "    ]\n",
    "\n",
    "    # Per-label metrics\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(y_true, y_pred, average=None, labels=class_labels)\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "\n",
    "    # Macro (unweighted) scores\n",
    "    precision_macro, recall_macro, f1_macro, _ = precision_recall_fscore_support(y_true, y_pred, average='macro', labels=class_labels)\n",
    "\n",
    "    # Macro (weighted) scores\n",
    "    precision_w, recall_w, f1_w, _ = precision_recall_fscore_support(y_true, y_pred, average='weighted', labels=class_labels)\n",
    "\n",
    "    # Error pairs\n",
    "    error_pairs = Counter((t, p) for t, p in zip(y_true, y_pred) if t != p)\n",
    "    sorted_errors = error_pairs.most_common()\n",
    "    for pair, count in sorted_errors:\n",
    "        print(f\"{pair}: {count}\")\n",
    "\n",
    "        # Convert to a DataFrame for readability\n",
    "    metrics_df = pd.DataFrame({\"Label\": class_labels, \"Accuracy\" : accuracy, \"Precision\": precision, \"Recall\": recall, \"F1-score\": f1})\n",
    "    # Display metrics\n",
    "\n",
    "    print(metrics_df)\n",
    "    print(f\"Macro Unweighted Metrics:\\nPrecision :{precision_macro} \\nRecall : {recall_macro} \\nF1-Score : {f1_macro}\")\n",
    "    print(f\"Weighted Metrics:\\nPrecision :{precision_w} \\nRecall : {recall_w} \\nF1-Score : {f1_w}\")\n",
    "\n",
    "\n",
    "    y_true_simplified = simplify_labels(y_true)\n",
    "    y_pred_simplied = simplify_labels(y_pred)\n",
    "\n",
    "    simplify_class_labels = [\n",
    "        \"surface\",\n",
    "        \"content\",\n",
    "        \"none\"\n",
    "    ]\n",
    "    # Compute per-label precision, recall, and F1-score\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(y_true_simplified, y_pred_simplied, average=None, labels=simplify_class_labels)\n",
    "    # Convert to a DataFrame for readability\n",
    "    metrics_simplified_df = pd.DataFrame({\"Label\": simplify_class_labels, \"Precision\": precision, \"Recall\": recall, \"F1-score\": f1})\n",
    "    print(metrics_simplified_df)\n",
    "\n",
    "    kappa = cohen_kappa_score(y_true, y_pred, weights='quadratic')\n",
    "    print(f\"Cohen's Kappa for fine granularity : {kappa:.4f}\")\n",
    "\n",
    "   \n",
    "    kappa = cohen_kappa_score(y_true_simplified, y_pred_simplied)\n",
    "    print(f\"Cohen's Kappa for coarse granularity : {kappa:.4f}\")\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nbl/anaconda3/lib/python3.10/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "def evaluate_ruan(results):\n",
    "    results = mapping_categories(results)\n",
    "    results[\"prediction\"] = results[\"prediction\"].str.lower()\n",
    "    results[\"Label\"] = results[\"Label\"].str.lower()\n",
    "    \n",
    "    y_true = results[\"Label\"].to_numpy()\n",
    "    y_pred = results[\"prediction\"].to_numpy()\n",
    "    \n",
    "    class_labels = [\n",
    "    \"clarity\",\n",
    "    \"grammar\",\n",
    "    \"claim\",\n",
    "    \"other\",\n",
    "    \"fact/evidence\",\n",
    "    ]\n",
    "\n",
    "    # Per-label metrics\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(y_true, y_pred, average=None, labels=class_labels)\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "\n",
    "    # Macro (unweighted) scores\n",
    "    precision_macro, recall_macro, f1_macro, _ = precision_recall_fscore_support(y_true, y_pred, average='macro', labels=class_labels)\n",
    "\n",
    "    # Macro (weighted) scores\n",
    "    precision_w, recall_w, f1_w, _ = precision_recall_fscore_support(y_true, y_pred, average='weighted', labels=class_labels)\n",
    "    # Error pairs\n",
    "    error_pairs = Counter((t, p) for t, p in zip(y_true, y_pred) if t != p)\n",
    "    sorted_errors = error_pairs.most_common()\n",
    "    for pair, count in sorted_errors:\n",
    "        print(f\"{pair}: {count}\")\n",
    "\n",
    "    # Convert to a DataFrame for readability\n",
    "    metrics_df = pd.DataFrame({\"Label\": class_labels, \"Accuracy\" : accuracy, \"Precision\": precision, \"Recall\": recall, \"F1-score\": f1})\n",
    "    # Display metrics\n",
    "    print(metrics_df)\n",
    "    print(f\"Macro Unweighted Metrics:\\nPrecision :{precision_macro} \\nRecall : {recall_macro} \\nF1-Score : {f1_macro}\")\n",
    "    print(f\"Weighted Metrics:\\nPrecision :{precision_w} \\nRecall : {recall_w} \\nF1-Score : {f1_w}\")\n",
    "\n",
    "\n",
    "    kappa = cohen_kappa_score(y_true, y_pred, weights='quadratic')\n",
    "    print(f\"Cohen's kappa: {kappa:.4f}\")\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DSPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dspy\n",
    "import tiktoken\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from collections import Counter\n",
    "from dspy.evaluate import Evaluate\n",
    "from dspy.teleprompt import BootstrapFewShotWithRandomSearch\n",
    "from typing import Literal\n",
    "\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import cohen_kappa_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 158\n"
     ]
    }
   ],
   "source": [
    "complete_train_df = pd.read_csv(\"/home/nbl/llm-notebooks/train_set_argRewrite_complete.csv\")\n",
    "\n",
    "gss = GroupShuffleSplit(n_splits=1, test_size=0.06, random_state=42)\n",
    "train_idxs, test_idxs = next(gss.split(complete_train_df, groups=complete_train_df[\"Doc Id\"]))\n",
    "\n",
    "train_df_dspy = complete_train_df.iloc[test_idxs]\n",
    "\n",
    "print(\"Training set size:\", len(train_df_dspy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_dspy.to_csv(\"training_set_dspy.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_dspy = pd.read_csv(\"/home/nbl/llm-notebooks/training_set_dspy.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = dspy.LM('openai/o3-mini', api_key='your_api_key', temperature=1.0, max_tokens=5000)\n",
    "dspy.configure(lm=lm)\n",
    "\n",
    "\n",
    "# Your 9 labels\n",
    "labels = [\n",
    "    \"word-usage/clarity\",\n",
    "    \"conventions/grammar/spelling\",\n",
    "    \"organization\",\n",
    "    \"general content development\",\n",
    "    \"precision\",\n",
    "    \"warrant/reasoning/backing\",\n",
    "    \"evidence\",\n",
    "    \"claims/ideas\",\n",
    "    \"rebuttal/reservation\"\n",
    "]\n",
    "\n",
    "# Define a DSPy module for classification\n",
    "class RevisionClassifier(dspy.Signature):\n",
    "    \"\"\"Classify the revision into one of 9 categories based on before/after text.\"\"\"\n",
    "    text_before_revision: str = dspy.InputField()\n",
    "    text_after_revision: str = dspy.InputField()\n",
    "    label: Literal['word-usage/clarity', 'conventions/grammar/spelling', 'organization', 'precision', 'general content development', 'rebuttal/reservation', 'claims/ideas', 'evidence', 'warrant/reasoning/backing'] = dspy.OutputField()\n",
    "\n",
    "# Wrap it into a DSPy program\n",
    "class ClassifyRevision(dspy.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.classifier = dspy.ChainOfThought(RevisionClassifier)\n",
    "\n",
    "    def forward(self, text_before_revision, text_after_revision):\n",
    "        return self.classifier(text_before_revision=text_before_revision, text_after_revision=text_after_revision)\n",
    "\n",
    "# Load your dataset as DSPy Examples\n",
    "def load_examples(df):\n",
    "    return [\n",
    "        dspy.Example(\n",
    "            text_before_revision=  row[\"Text Before\"],\n",
    "            text_after_revision= row[\"Text After\"],\n",
    "            label= row[\"Label\"].lower()\n",
    "        ).with_inputs(\"text_before_revision\", \"text_after_revision\")\n",
    "        for _, row in df.iterrows()\n",
    "    ]\n",
    "\n",
    "def validate_answer(example, pred, trace=None):\n",
    "    return example.label.lower() == pred.label.lower()\n",
    "\n",
    "# Optional: optimize prompt with few-shot examples\n",
    "def optimize_with_bootstrap(train_examples):\n",
    "    teleprompter = dspy.BootstrapFewShotWithRandomSearch(metric=validate_answer, num_candidate_programs=10)\n",
    "\n",
    "    program = ClassifyRevision()\n",
    "    optimized_program = teleprompter.compile(program, trainset=train_examples)\n",
    "\n",
    "    return optimized_program\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Assuming you have a DataFrame called df with 'text_before', 'text_after', 'label'\n",
    "df = train_df_dspy\n",
    "test_df = pd.read_csv(\"/home/nbl/llm-notebooks/test_set_argRewrite_complete.csv\")\n",
    "train_data = load_examples(df)\n",
    "test_data = load_examples(test_df)\n",
    "\n",
    "\n",
    "# Train (optimize prompt + weights)\n",
    "optimized_model = optimize_with_bootstrap(train_data)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "import pandas as pd\n",
    "\n",
    "# Collect predictions\n",
    "preds = []\n",
    "golds = []\n",
    "\n",
    "for ex in test_data:\n",
    "    output = optimized_model.forward(**ex.inputs)\n",
    "    pred = output.label\n",
    "    gold = ex.outputs[\"label\"]\n",
    "\n",
    "    preds.append(pred)\n",
    "    golds.append(gold)\n",
    "\n",
    "    print(f\"Gold: {gold} | Pred: {pred}\")\n",
    "\n",
    "# Save predictions to CSV\n",
    "df_preds = pd.DataFrame({\n",
    "    \"Label\": golds,\n",
    "    \"prediction\": preds\n",
    "})\n",
    "df_preds.to_csv(\"revision_predictions.csv\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(df_preds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
